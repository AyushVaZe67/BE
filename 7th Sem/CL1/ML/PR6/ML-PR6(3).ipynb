{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3658fbc4-1aa6-47fc-a0dc-2c5db940ca79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Final epsilon: 0.05\n",
      "Test Results: {'win': 408, 'loss': 63, 'draw': 29}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# =====================================================\n",
    "# a. Setting up the environment\n",
    "# =====================================================\n",
    "class TicTacToeEnv:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = [' '] * 9  # 3x3 board\n",
    "        self.done = False\n",
    "        self.winner = None\n",
    "        return self.get_state()\n",
    "\n",
    "    def get_state(self):\n",
    "        return ''.join(self.board)\n",
    "\n",
    "    def available_actions(self):\n",
    "        return [i for i, v in enumerate(self.board) if v == ' ']\n",
    "\n",
    "    def step(self, action, player):\n",
    "        if self.board[action] != ' ' or self.done:\n",
    "            return self.get_state(), -10, True  # illegal move\n",
    "        self.board[action] = player\n",
    "\n",
    "        # Check if game ended\n",
    "        self.winner = self.check_winner()\n",
    "        if self.winner:\n",
    "            self.done = True\n",
    "            return self.get_state(), 1 if self.winner == 'X' else -1, True\n",
    "        elif ' ' not in self.board:\n",
    "            self.done = True\n",
    "            return self.get_state(), 0.5, True  # draw\n",
    "        else:\n",
    "            return self.get_state(), 0, False\n",
    "\n",
    "    def check_winner(self):\n",
    "        combos = [\n",
    "            [0,1,2],[3,4,5],[6,7,8], # rows\n",
    "            [0,3,6],[1,4,7],[2,5,8], # cols\n",
    "            [0,4,8],[2,4,6]          # diagonals\n",
    "        ]\n",
    "        for a,b,c in combos:\n",
    "            if self.board[a] == self.board[b] == self.board[c] and self.board[a] != ' ':\n",
    "                return self.board[a]\n",
    "        return None\n",
    "\n",
    "    def render(self):\n",
    "        print(\"\\n\".join([\"|\".join(self.board[i:i+3]) for i in range(0,9,3)]))\n",
    "        print(\"-----\")\n",
    "\n",
    "# =====================================================\n",
    "# b. Defining the Tic-Tac-Toe game (already done above)\n",
    "# =====================================================\n",
    "\n",
    "# =====================================================\n",
    "# c. Building the reinforcement learning model (Q-learning)\n",
    "# =====================================================\n",
    "class QLearningAgent:\n",
    "    def __init__(self, player='X', alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_decay=0.9995, epsilon_min=0.05):\n",
    "        self.q_table = defaultdict(float)  # maps (state, action) â†’ value\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.player = player\n",
    "\n",
    "    def choose_action(self, state, available_actions):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(available_actions)\n",
    "        q_vals = [self.q_table[(state, a)] for a in available_actions]\n",
    "        max_q = max(q_vals)\n",
    "        best_actions = [a for a in available_actions if self.q_table[(state, a)] == max_q]\n",
    "        return random.choice(best_actions)\n",
    "\n",
    "    def update(self, state, action, reward, next_state, next_available, done):\n",
    "        best_next = 0 if done else max([self.q_table[(next_state, a)] for a in next_available], default=0)\n",
    "        old_value = self.q_table[(state, action)]\n",
    "        self.q_table[(state, action)] = old_value + self.alpha * (reward + self.gamma * best_next - old_value)\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "# =====================================================\n",
    "# d. Training the model\n",
    "# =====================================================\n",
    "def train(agent, episodes=50000):\n",
    "    env = TicTacToeEnv()\n",
    "    opponent = 'O' if agent.player == 'X' else 'X'\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        current_player = 'X'\n",
    "\n",
    "        while not done:\n",
    "            if current_player == agent.player:\n",
    "                action = agent.choose_action(state, env.available_actions())\n",
    "                next_state, reward, done = env.step(action, agent.player)\n",
    "                agent.update(state, action, reward, next_state, env.available_actions(), done)\n",
    "                state = next_state\n",
    "                if done: \n",
    "                    break\n",
    "            else:\n",
    "                # Opponent plays randomly\n",
    "                action = random.choice(env.available_actions())\n",
    "                next_state, reward, done = env.step(action, opponent)\n",
    "                state = next_state\n",
    "                if done: \n",
    "                    # If opponent wins, negative reward to agent\n",
    "                    if env.winner == opponent:\n",
    "                        agent.update(state, action, -1, next_state, env.available_actions(), done)\n",
    "                    break\n",
    "            current_player = opponent if current_player == agent.player else agent.player\n",
    "\n",
    "        agent.decay_epsilon()\n",
    "\n",
    "    print(\"Training complete. Final epsilon:\", agent.epsilon)\n",
    "\n",
    "# =====================================================\n",
    "# e. Testing the model\n",
    "# =====================================================\n",
    "def test(agent, games=20):\n",
    "    env = TicTacToeEnv()\n",
    "    opponent = 'O' if agent.player == 'X' else 'X'\n",
    "    results = {\"win\": 0, \"loss\": 0, \"draw\": 0}\n",
    "\n",
    "    for _ in range(games):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        current_player = 'X'\n",
    "\n",
    "        while not done:\n",
    "            if current_player == agent.player:\n",
    "                action = agent.choose_action(state, env.available_actions())\n",
    "                state, reward, done = env.step(action, agent.player)\n",
    "            else:\n",
    "                action = random.choice(env.available_actions())\n",
    "                state, reward, done = env.step(action, opponent)\n",
    "\n",
    "            if done:\n",
    "                if env.winner == agent.player:\n",
    "                    results[\"win\"] += 1\n",
    "                elif env.winner == opponent:\n",
    "                    results[\"loss\"] += 1\n",
    "                else:\n",
    "                    results[\"draw\"] += 1\n",
    "                break\n",
    "            current_player = opponent if current_player == agent.player else agent.player\n",
    "\n",
    "    print(\"Test Results:\", results)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# Run training and testing\n",
    "# =====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    agent = QLearningAgent(player='X')\n",
    "    train(agent, episodes=50000)   # Train agent\n",
    "    test(agent, games=500)          # Test agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b115d18-d528-438b-a0a8-162423b9c0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
